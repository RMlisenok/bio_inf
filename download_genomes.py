import os
import requests
from bs4 import BeautifulSoup

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
ENSEMBL_RELEASE = '113'
GENOME_DIR = './genomes'
SPECIES_LIST = [
    "homo_sapiens",
    "pan_troglodytes",
    "mus_musculus",
    "rattus_norvegicus",
    "canis_lupus_familiaris",
    "bos_taurus",
    "gallus_gallus",
    "danio_rerio",
    "drosophila_melanogaster",
    "caenorhabditis_elegans"
    "saccharomyces_cerevisiae"
]

def download_genome(species, filename_contains="dna.toplevel.fa.gz"):
    base_url = f"https://ftp.ensembl.org/pub/release-{ENSEMBL_RELEASE}/fasta/{species}/dna/"
    output_dir = os.path.join(GENOME_DIR, species)
    os.makedirs(output_dir, exist_ok=True)

    try:
        print(f"\nüîç –û–±—Ä–∞–±–æ—Ç–∫–∞: {species}")
        r = requests.get(base_url)
        r.raise_for_status()

        soup = BeautifulSoup(r.text, "html.parser")
        for link in soup.find_all("a"):
            href = link.get("href")
            if href and filename_contains in href:
                full_url = base_url + href
                print(f"‚¨áÔ∏è  –°–∫–∞—á–∏–≤–∞–Ω–∏–µ: {full_url}")
                file_response = requests.get(full_url, stream=True)
                file_response.raise_for_status()

                local_path = os.path.join(output_dir, href)
                with open(local_path, 'wb') as f:
                    for chunk in file_response.iter_content(chunk_size=8192):
                        f.write(chunk)
                print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {local_path}")
                return
        print(f"‚ö†Ô∏è  –§–∞–π–ª '{filename_contains}' –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {species}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {species}: {e}")

def main():
    print("üöÄ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≥–µ–Ω–æ–º–æ–≤ Ensembl Release", ENSEMBL_RELEASE)
    for species in SPECIES_LIST:
        download_genome(species)
    print("üèÅ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

if __name__ == "__main__":
    main()
